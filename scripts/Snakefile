import pandas as pd
configfile: "./config.yaml"

DIR = config["in_dir"]
SAMPLES = pd.read_csv(config["sample_file"])['Sample']
EXP=config["experiment_id"]
SEQ_RUN=config["seq_run"] #"langlois044_all"

rule all:
    input: 
        expand("../salmon_indices/{seq_run}/{experiment_id}_unmapped_index", seq_run=SEQ_RUN, experiment_id=EXP),
        expand("../salmon_quant_results/{seq_run}/{experiment_id}/{sample}_unmapped_quant/quant.sf", sample=SAMPLES, experiment_id=EXP, seq_run=SEQ_RUN),
        expand("../final/{seq_run}/{exp}/{exp}_sorted_blast.txt", exp=EXP, seq_run=SEQ_RUN),
        expand("../final/{seq_run}/{exp}/{exp}_transcript_lineages.csv", exp=EXP, seq_run=SEQ_RUN),
        expand("../final/{seq_run}/{exp}/{exp}_sp_counts.csv", exp=EXP, seq_run=SEQ_RUN),
        expand("../final/{seq_run}/{exp}/{exp}_family_counts.csv", exp=EXP, seq_run=SEQ_RUN)

rule salmon_index:
    input:
        config["trinity_file"]
    output:
        directory("../salmon_indices/{seq_run}/{experiment_id}_unmapped_index"),
    log:
        "../logs/salmon/{seq_run}/{experiment_id}.index.log"
    shell:
        """
        salmon index -t {input} -i {output} -p 16 > {log}
        """

rule salmon_quant:
    input:
        r1 = expand("{dir}/{{sample}}_R1_001.fastq.gz", dir=DIR),
        r2 = expand("{dir}/{{sample}}_R2_001.fastq.gz", dir=DIR),
        index = "../salmon_indices/{seq_run}/{experiment_id}_unmapped_index"
    output:
        "../salmon_quant_results/{seq_run}/{experiment_id}/{sample}_unmapped_quant/quant.sf"
    params:
        dir = directory("../salmon_quant_results/{seq_run}/{experiment_id}/{sample}_unmapped_quant")
    threads:
        16
    log:
        "../logs/salmon_quant/{seq_run}/{experiment_id}/{sample}.log"
    shell:
        """
        salmon quant -i {input.index} \
            -l A \
            -1 {input.r1} \
            -2 {input.r2} \
            --threads {threads} \
            --seqBias \
            --gcBias \
            -o {params.dir} > {log}
        """

rule concatenate_blast:
    input:
        expand("../blast_results/{seq_run}/{exp}_blast_results/", exp=EXP, seq_run=SEQ_RUN)
    output:
        expand("../final/{seq_run}/{exp}/{exp}_sorted_blast.txt", exp=EXP, seq_run=SEQ_RUN)
    shell:
        '''
        cat {input}/*.out | sort -k 1,1 -k4,4nr | sort -u -k1,1 --merge > {output}
        '''

rule assign_lineages:
    input:
        blast = expand("../final/{seq_run}/{exp}/{exp}_sorted_blast.txt", exp=EXP, seq_run=SEQ_RUN),
        nodes = "/panfs/roc/groups/9/langlois/shared/taxdump2021/nodes.dmp",
        names = "/panfs/roc/groups/9/langlois/shared/taxdump2021/names.dmp"
    output:
        expand("../final/{seq_run}/{exp}/{exp}_transcript_lineages.csv", exp=EXP, seq_run=SEQ_RUN)
    shell:
        '''
        cut -f6,7 {input.blast} | sed 's/;.*//;s/\t/,/g' > {EXP}_lineage.csv
        python ./2018-ncbi-lineages/make-lineage-csv.py \
            {input.nodes} {input.names} \
            {EXP}_lineage.csv \
            -o {output}
        sed -i '1i trinity_id\tqseqid\tsseqid\tevalue\tbitscore\tsgi\tsacc\tstaxids\tsscinames\tscomnames\tstitle' {input.blast}
        cut -f1 {input.blast} | paste -d, - {output} > tmp.csv
        mv tmp.csv {output}
        rm {EXP}_lineage.csv
        '''

rule summarize_transcripts:
    input:
        lineages = expand("../final/{seq_run}/{exp}/{exp}_transcript_lineages.csv", exp=EXP, seq_run=SEQ_RUN),
        salmon_files = expand("../salmon_quant_results/{seq_run}/{experiment_id}/{sample}_unmapped_quant/quant.sf", sample=SAMPLES, experiment_id=EXP, seq_run=SEQ_RUN),
    output:
        species_counts = expand("../final/{seq_run}/{exp}/{exp}_sp_counts.csv", exp=EXP, seq_run=SEQ_RUN),
        family_counts = expand("../final/{seq_run}/{exp}/{exp}_family_counts.csv", exp=EXP, seq_run=SEQ_RUN)        
    script:
        "deseq2.R"
        
